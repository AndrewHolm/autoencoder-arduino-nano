{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+qG3B/toqxHYY4pHX2WoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewHolm/autoencoder-arduino-nano/blob/main/autoencoder_accel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "apuKmJOf2MDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data from arduino (200 1 second samples at 50hz in 3 dimmensions)\n",
        "# Pull side is a sharp left swipe with the arduino pointed at the screen (y), z least change\n",
        "# Pull up is a sharp swipe up with arduino starting pointing at screen (y), x least change\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('accel_up_left_data.csv')\n",
        "\n",
        "# Extract the moving and not moving data into separate arrays\n",
        "pull_side = df['pull_side'].to_numpy()\n",
        "pull_up = df['pull_up'].to_numpy()\n",
        "print(pull_side.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIYaqu9j15Uw",
        "outputId": "445aa430-c3ef-4bdf-bbd8-386051339214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pull_up = pull_up.reshape(200, 50, 3)\n",
        "pull_side = pull_side.reshape(200, 50, 3)\n",
        "\n",
        "\n",
        "# Normalize the data (zero mean and unit variance)\n",
        "# Reshape the data to have shape (4200*50, 3) for normalization\n",
        "\n",
        "normalized_data_up = pull_up.reshape(-1, 3)\n",
        "normalized_data_side = pull_side.reshape(-1, 3)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "normalized_data_up = scaler.fit_transform(normalized_data_up)\n",
        "\n",
        "normalized_data_side = scaler.fit_transform(normalized_data_side)\n",
        "\n",
        "# Reshape the normalized data back to the original shape (400, 50, 3)\n",
        "normalized_data_up = normalized_data_up.reshape(pull_up.shape)\n",
        "normalized_data_side = normalized_data_side.reshape(pull_side.shape)\n",
        "\n",
        "raw_data = np.concatenate((normalized_data_side, normalized_data_up), axis=0) # combine (400, 50, 3)\n",
        "\n",
        "# Create labels for the data\n",
        "num_samples, sample_rate, dim = raw_data.shape # num_samples = 400, sample_rate = 50\n",
        "\n",
        "# create array for lables, 200 to represent side swipe (0), 200 to represent up swipe (1)\n",
        "labels = np.concatenate((np.zeros(num_samples//2), np.ones(num_samples//2)))\n",
        "\n",
        "\n",
        "\n",
        "# x_train -> data y_train -> labels, use 75% for training/ 25% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(raw_data, labels, test_size=0.25, random_state=42)\n",
        "sample1 = raw_data.reshape(400,150)"
      ],
      "metadata": {
        "id": "MHDHE4T62Eak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "normalized_data = sample1\n",
        "\n",
        "input_dim = normalized_data.shape[1]\n",
        "# compression size\n",
        "latent_dim = 64\n",
        "\n",
        "# Create the encoder model\n",
        "encoder = Sequential()\n",
        "encoder.add(Dense(128, activation='relu', input_shape=(input_dim,)))\n",
        "encoder.add(Dense(latent_dim, activation='relu'))\n",
        "\n",
        "# Create the decoder model\n",
        "decoder = Sequential()\n",
        "decoder.add(Dense(128, activation='relu', input_shape=(latent_dim,)))\n",
        "decoder.add(Dense(input_dim, activation='linear'))\n",
        "\n",
        "# Combine the encoder and decoder models into the autoencoder model\n",
        "autoencoder = Sequential([encoder, decoder])\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "train_data, val_data = train_test_split(normalized_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training\n",
        "autoencoder.fit(train_data, train_data, epochs=100, batch_size=32, shuffle=True, validation_data=(val_data, val_data))\n",
        "\n",
        "# Compression and Decompression\n",
        "encoded_data = encoder.predict(normalized_data)\n",
        "reconstructed_data = decoder.predict(encoded_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXunzLBGIE_0",
        "outputId": "4225c2bc-1049-4e18-aed9-469a1f2f8107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 17ms/step - loss: 0.9692 - val_loss: 0.7690\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.7599 - val_loss: 0.6060\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6107 - val_loss: 0.4975\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.5100 - val_loss: 0.4319\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.4404 - val_loss: 0.3888\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3970 - val_loss: 0.3598\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3606 - val_loss: 0.3411\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3347 - val_loss: 0.3256\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3097 - val_loss: 0.3145\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2911 - val_loss: 0.3060\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2733 - val_loss: 0.2973\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2579 - val_loss: 0.2902\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2435 - val_loss: 0.2833\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.2324 - val_loss: 0.2785\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2208 - val_loss: 0.2726\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2093 - val_loss: 0.2671\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2007 - val_loss: 0.2627\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1928 - val_loss: 0.2584\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1866 - val_loss: 0.2562\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1802 - val_loss: 0.2528\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1741 - val_loss: 0.2484\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1683 - val_loss: 0.2463\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1635 - val_loss: 0.2436\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1591 - val_loss: 0.2398\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1542 - val_loss: 0.2377\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1499 - val_loss: 0.2348\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1456 - val_loss: 0.2339\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1419 - val_loss: 0.2307\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1389 - val_loss: 0.2299\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1351 - val_loss: 0.2275\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1318 - val_loss: 0.2269\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1295 - val_loss: 0.2249\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1262 - val_loss: 0.2240\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1230 - val_loss: 0.2222\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.2213\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1180 - val_loss: 0.2187\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1153 - val_loss: 0.2174\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1130 - val_loss: 0.2162\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1104 - val_loss: 0.2138\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1082 - val_loss: 0.2144\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.1064 - val_loss: 0.2136\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.1044 - val_loss: 0.2110\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 0.1025 - val_loss: 0.2105\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1006 - val_loss: 0.2100\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0989 - val_loss: 0.2090\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0973 - val_loss: 0.2072\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0955 - val_loss: 0.2074\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0942 - val_loss: 0.2061\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0928 - val_loss: 0.2062\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0913 - val_loss: 0.2044\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0897 - val_loss: 0.2038\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0887 - val_loss: 0.2040\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0877 - val_loss: 0.2033\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0865 - val_loss: 0.2021\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0847 - val_loss: 0.2020\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.1997\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0825 - val_loss: 0.2006\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0816 - val_loss: 0.1999\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0806 - val_loss: 0.1986\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0795 - val_loss: 0.1995\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.1974\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0773 - val_loss: 0.1982\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0766 - val_loss: 0.1969\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0754 - val_loss: 0.1969\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0747 - val_loss: 0.1970\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0741 - val_loss: 0.1954\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0732 - val_loss: 0.1957\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0721 - val_loss: 0.1938\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.1952\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.1939\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0697 - val_loss: 0.1940\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0693 - val_loss: 0.1932\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.1935\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0679 - val_loss: 0.1928\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0669 - val_loss: 0.1935\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.1927\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0656 - val_loss: 0.1920\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0650 - val_loss: 0.1919\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0643 - val_loss: 0.1915\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0636 - val_loss: 0.1915\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0628 - val_loss: 0.1908\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0623 - val_loss: 0.1901\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0618 - val_loss: 0.1906\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.1894\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0606 - val_loss: 0.1898\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.1886\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0596 - val_loss: 0.1891\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0590 - val_loss: 0.1886\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.1887\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0581 - val_loss: 0.1892\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0579 - val_loss: 0.1885\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.1875\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0569 - val_loss: 0.1882\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0566 - val_loss: 0.1885\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0562 - val_loss: 0.1891\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0562 - val_loss: 0.1880\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.1884\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0548 - val_loss: 0.1869\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0546 - val_loss: 0.1885\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0545 - val_loss: 0.1885\n",
            "13/13 [==============================] - 0s 1ms/step\n",
            "13/13 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(encoder)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# convert to a c header file\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "!xxd -i model.tflite > encoder.h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmTI1NU86_3w",
        "outputId": "7fce0a38-1750-48e4-c63d-a6d528bccdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "\r            \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/114\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,012 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,059 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,351 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,779 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,259 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:16 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,489 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,355 kB]\n",
            "Fetched 14.6 MB in 2s (7,789 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(reconstructed_data[120])\n",
        "# print(normalized_data[120])\n",
        "print(encoded_data[0])\n",
        "print(encoded_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hUMEh2a-h8r",
        "outputId": "8e9b3fc1-828b-459f-d064-29fd615a9823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31626737 0.         1.5823089  0.51153034 1.7711321  0.\n",
            " 1.6641611  1.4744486  3.0693388  2.2044382  0.8072093  0.80888855\n",
            " 2.5725346  0.5803729  1.4528929  0.49476996 0.26514265 3.0514514\n",
            " 0.621678   0.93526906 0.         0.989805   1.5376823  0.\n",
            " 0.         0.44638196 0.         0.         1.5941517  0.\n",
            " 0.         0.5660197  0.         0.17064214 0.         0.\n",
            " 1.2886528  0.52150565 0.68582064 1.0517743  1.8238121  1.7886131\n",
            " 2.2726376  2.2980254  0.94821095 0.         1.1249874  1.6019126\n",
            " 0.         1.4227327  0.96348584 0.         1.048302   2.4122872\n",
            " 0.         1.6578296  2.1278427  0.         0.61143535 1.1489259\n",
            " 4.2285404  0.         0.         2.678676  ]\n",
            "(400, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy encoded data from arduino\n",
        "enc_up1 = np.array([0.00, 0.00, 0.00, 0.00, 1.70, 3.17, 3.28, 4.24, 3.08, 2.38, 1.66, 3.51, 0.00, 0.71, 0.00, 0.00, 1.98, 2.47, 1.19, 0.00, 2.16, 2.25, 1.04, 0.00, 0.00, 0.04, 1.79, 0.00, 1.86, 0.70, 0.00, 0.13, 3.93, 1.65, 0.00, 0.91, 1.11, 0.14, 0.16, 1.81, 2.58, 2.29, 0.89, 0.00, 0.00, 0.00, 0.98, 1.72, 0.33, 0.00, 0.00, 2.63, 5.83, 0.58, 2.42, 0.00, 0.00, 0.00, 0.70, 1.52, 0.00, 0.00, 2.52, 2.45])\n",
        "enc_up2 = np.array([0.00, 0.00, 0.00, 0.00, 2.08, 1.32, 4.29, 3.66, 4.14, 2.74, 1.66, 3.74, 0.00, 0.20, 0.00, 0.00, 1.80, 1.86, 1.40, 0.17, 3.67, 2.55, 0.80, 0.00, 0.00, 0.00, 1.44, 0.00, 1.61, 0.79, 0.00, 0.49, 4.12, 1.13, 0.00, 0.04, 1.39, 0.00, 0.54, 0.99, 3.91, 2.38, 0.65, 0.00, 0.27, 0.07, 0.64, 2.21, 0.00, 0.00, 0.00, 2.57, 6.06, 2.21, 1.83, 1.09, 0.00, 0.00, 1.30, 2.59, 1.53, 0.00, 2.47, 2.68])\n",
        "enc_left1 = np.array([0.00, 0.00, 0.00, 0.39, 0.66, 1.82, 1.87, 3.13, 1.50, 3.58, 1.50, 3.89, 0.00, 0.90, 0.00, 0.84, 0.50, 2.84, 0.02, 1.62, 2.65, 2.54, 0.33, 0.00, 0.53, 1.77, 0.86, 0.25, 0.89, 0.00, 0.00, 1.21, 0.14, 3.13, 0.00, 0.00, 1.22, 1.09, 2.50, 1.86, 2.69, 3.49, 0.00, 0.43, 0.79, 0.00, 0.00, 2.42, 0.00, 0.00, 1.13, 3.48, 5.63, 3.21, 1.28, 0.59, 0.00, 1.58, 2.03, 0.45, 3.24, 0.00, 0.00, 2.78])\n",
        "enc_left2 = np.array([0.00, 0.00, 0.00, 1.10, 1.34, 1.21, 2.80, 2.76, 2.58, 3.70, 2.07, 3.95, 1.36, 2.46, 0.00, 1.30, 1.36, 1.47, 1.11, 0.46, 0.57, 1.09, 0.92, 1.01, 0.09, 4.16, 0.28, 0.00, 0.00, 1.43, 0.00, 0.91, 1.22, 2.87, 0.00, 0.00, 0.50, 1.35, 1.45, 2.89, 0.35, 2.70, 0.00, 0.09, 0.83, 0.00, 0.00, 1.08, 0.00, 0.58, 1.87, 0.00, 3.37, 0.75, 0.52, 0.00, 0.19, 0.00, 1.07, 1.24, 2.00, 0.00, 0.00, 2.00])"
      ],
      "metadata": {
        "id": "B-_Yjn28BTKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the reconstructed data (decoding data encoded on arduino)\n",
        "recon_up1 = decoder.predict(np.expand_dims(enc_up1, axis=0))\n",
        "recon_up2 = decoder.predict(np.expand_dims(enc_up2, axis=0))\n",
        "recon_left1 = decoder.predict(np.expand_dims(enc_left1, axis=0))\n",
        "recon_left2 = decoder.predict(np.expand_dims(enc_left2, axis=0))\n",
        "\n",
        "# recon_up2 = decoder.predict(enc_up2)\n",
        "# recon_left1 = decoder.predict(enc_left1)\n",
        "# recon_left2 = decoder.predict(enc_left2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xut5a5C7BzVH",
        "outputId": "262883c3-5d8f-4dcf-d77d-3fc093cf4ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(recon_up1)\n",
        "print(recon_left1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIj0VUNIDCgp",
        "outputId": "db049da3-2508-462e-9666-a460d2dd2680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.1777471  -0.7864548  -0.00423748 -0.8340096  -0.06436472  0.34946492\n",
            "  -1.1564169  -0.05503287  0.9681298  -0.79453564 -0.04033934  0.43210274\n",
            "  -0.85697013 -0.73426     0.1606679  -0.740796   -0.8960267   0.45226198\n",
            "  -0.8975558  -0.65448135  0.43582588 -0.81091267 -0.62177163  0.11555614\n",
            "  -0.5283816  -0.46913233  0.17871419 -0.4469193  -0.06338474  0.5099238\n",
            "  -1.0789574  -0.32392624  1.1360737  -1.139829   -0.6882303   0.59058195\n",
            "  -1.3187705  -0.8289567   0.18980551 -0.9374849  -0.9057495  -0.01976958\n",
            "  -0.86100405 -0.32776693  0.80619764 -0.78914535 -0.17817602  1.8191425\n",
            "  -0.80221725 -0.39467627  0.8627856  -0.9274314  -1.9319025   0.38428134\n",
            "  -0.98266745 -1.1330926   1.5092047  -1.0848328  -0.28474286  1.4670451\n",
            "  -1.1392585  -0.23618406  1.4188731  -1.2222731  -0.8258652   0.9797459\n",
            "  -1.1400794  -0.7946047   1.1580204  -1.058196   -0.55253184  1.133884\n",
            "  -0.97304857 -0.91278315  0.7961787  -0.905085   -1.257393    0.9198602\n",
            "  -0.6960232  -1.0807447   1.0068597  -0.87821966 -0.43703592  0.6504998\n",
            "  -0.773211   -0.6731069   0.85408866 -0.53740597 -1.2548575   1.0861162\n",
            "  -0.3042837  -0.9382829   0.9640347  -0.47642326 -0.13679475  0.6976352\n",
            "  -0.28595975 -0.27095112  0.5147561  -0.66552263 -0.87392294  0.642138\n",
            "  -0.36557385 -0.72190803  0.70206493 -0.3953172  -0.16485943  0.98835796\n",
            "  -0.31909657  0.01729093  0.43698177 -0.2064474  -0.7660377   0.7821747\n",
            "  -0.25467318 -0.74635744  0.33721063 -0.06452458 -0.78694296  0.40681913\n",
            "   0.00510805 -0.525669    0.5008637   0.21955626 -0.15782818  0.63299465\n",
            "  -0.0394196  -0.06597765  0.48358896 -0.09733142 -0.39380327 -0.20537803\n",
            "  -0.1028237  -0.6030918  -0.93093944 -0.38531628 -0.61622435 -1.0450478\n",
            "  -0.470678   -0.10417651 -1.7092144  -0.32688996 -0.3926968  -1.3687656\n",
            "   0.24991335  0.80113965 -2.3470612   0.3165474   1.0343411  -2.796432  ]]\n",
            "[[-1.02946937e+00 -2.80162320e-03  1.64181018e+00 -6.78139329e-02\n",
            "   4.96395200e-01  6.03608727e-01 -7.32032210e-02  2.19769493e-01\n",
            "  -3.65587384e-01 -6.14086390e-01 -9.50006783e-01  4.53757346e-01\n",
            "  -9.27616477e-01 -8.58906448e-01  9.02978003e-01 -1.03223777e+00\n",
            "  -8.76523674e-01  1.73318458e+00 -7.84022331e-01 -8.46169889e-01\n",
            "   5.59037440e-02 -1.40125453e-01 -5.88543773e-01  5.52541539e-02\n",
            "   4.19327691e-02 -2.89883792e-01  4.72239733e-01 -1.49715498e-01\n",
            "  -6.09961748e-01  3.23240995e-01 -7.87397921e-02 -2.94534445e-01\n",
            "   1.01024640e+00  8.69919956e-02 -3.68097872e-01  1.08032870e+00\n",
            "  -6.30977213e-01 -1.66533124e+00 -5.79486668e-01 -2.82112271e-01\n",
            "  -1.57513130e+00  8.18182528e-02 -6.89560592e-01 -1.12855411e+00\n",
            "   1.75385758e-01 -9.34694648e-01 -1.29738915e+00  1.01298392e+00\n",
            "  -7.93896735e-01 -1.33652437e+00  5.97888887e-01 -1.04516053e+00\n",
            "  -3.06321597e+00  5.85496962e-01 -1.08364940e+00 -2.44766164e+00\n",
            "  -6.49004161e-01 -8.84186625e-01 -9.23007965e-01  8.79788458e-01\n",
            "  -1.11742449e+00 -8.82224202e-01  9.88206863e-01 -9.14628446e-01\n",
            "  -9.21012521e-01  4.40655351e-01 -6.78745508e-01 -8.86243403e-01\n",
            "   8.24685454e-01 -1.09545553e+00 -8.07858348e-01  1.23296428e+00\n",
            "  -1.26408660e+00 -1.53932858e+00  1.82331651e-01 -1.33277977e+00\n",
            "  -1.34799814e+00  3.48480642e-01 -1.43454337e+00 -4.41599250e-01\n",
            "   1.11045504e+00 -1.42624938e+00 -1.12835395e+00  1.17099476e+00\n",
            "  -1.40756118e+00 -1.08330929e+00  2.89231420e-01 -1.10871279e+00\n",
            "  -5.93243539e-01 -2.28636652e-01 -7.79052913e-01 -1.06821036e+00\n",
            "   8.60736668e-01 -1.33436823e+00 -5.48123419e-01  9.43205178e-01\n",
            "  -1.35084856e+00 -8.32840204e-01  1.95742056e-01 -1.60041642e+00\n",
            "  -1.38249505e+00 -2.39110529e-01 -1.02565920e+00 -1.01166892e+00\n",
            "   6.58547759e-01 -1.14000928e+00 -1.05124545e+00  6.09014809e-01\n",
            "  -1.16438246e+00 -1.21672630e+00  1.39329255e-01 -1.15311837e+00\n",
            "  -1.63079381e-01  9.24778804e-02 -8.15488458e-01 -5.98573625e-01\n",
            "   5.39996982e-01 -8.20104003e-01 -4.68631029e-01  5.03195703e-01\n",
            "  -6.31414473e-01 -3.52368683e-01  5.79805017e-01 -4.65142518e-01\n",
            "   1.06035578e+00  5.68037748e-01 -3.61621082e-01  2.50477314e+00\n",
            "   7.47592807e-01 -3.65999490e-01  1.31941664e+00  8.25555861e-01\n",
            "   2.30715856e-01  1.78433990e+00  5.97189784e-01  2.49171451e-01\n",
            "   2.77326369e+00  1.25357437e+00 -2.70114541e-01  1.83145201e+00\n",
            "   5.69530249e-01 -7.95754135e-01  1.11661829e-01 -1.00901246e-01\n",
            "  -3.97407591e-01  1.41951180e+00 -4.66871619e-01 -6.94584489e-01\n",
            "   1.35801136e+00 -1.77849293e-01]]\n"
          ]
        }
      ]
    }
  ]
}